{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introdu\u00e7\u00e3o Documenta\u00e7\u00e3o para a an\u00e1lise de dados e para modifica\u00e7\u00e3o do scraper. O projeto consiste em um WebScraper ,utilizando a biblioteca Scrapy, que coleta notas de reviews dos jogos e os salva em um arquivo json, assim com esse arquivo podemos fazer uma an\u00e1lise. O site utilizado para os dados foi: http://gameinformer.com/reviews. An\u00e1lise de Dados Scraper","title":"Home"},{"location":"#introducao","text":"Documenta\u00e7\u00e3o para a an\u00e1lise de dados e para modifica\u00e7\u00e3o do scraper. O projeto consiste em um WebScraper ,utilizando a biblioteca Scrapy, que coleta notas de reviews dos jogos e os salva em um arquivo json, assim com esse arquivo podemos fazer uma an\u00e1lise. O site utilizado para os dados foi: http://gameinformer.com/reviews.","title":"Introdu\u00e7\u00e3o"},{"location":"#analise-de-dados","text":"","title":"An\u00e1lise de Dados"},{"location":"#scraper","text":"","title":"Scraper"},{"location":"dados/","text":"An\u00e1lise de Dados Primeiro \u00e9 necess\u00e1rio baixar as depend\u00eancias: pandas : pip install pandas matplotlib : pip install matplolib numpy : pip install numpy O WebScraper, al\u00e9m de coletar as notas dos jogos, obteve outros par\u00e2metros para fazer uma an\u00e1lise. Os par\u00e2metros coletados no projeto foram t\u00edtulo, nota, publisher, desenvolvedora e lan\u00e7amento, apresentado no arquivo json. Ap\u00f3s a coleta e o arquivo GameInformer.json criado a \u00e1nalise pode ser feita. Assim, no arquivo An\u00e1lise dos dados.ipynb est\u00e1 a an\u00e1lise do projeto. Duas an\u00e1lises foram apresentadas, a primeira foi a distribui\u00e7\u00e3o das notas dos jogos. E a segunda foi as notas dos jogos das seguintes distribuidoras: Nintendo, Sony Interactive Entertainment (Playstation) e Xbox Game Studios, para saber qual das empresas tem as melhores notas. Distribui\u00e7\u00e3o das notas dos jogos: Nintendo x Playstation x Xbox: Como mencionado anteriormente, houve uma coleta de outros par\u00e2metros pelo WebScraper, podendo futuramente fazer outros tipos de an\u00e1lises envolvendo esses dados.","title":"Dados"},{"location":"dados/#analise-de-dados","text":"","title":"An\u00e1lise de Dados"},{"location":"dados/#primeiro-e-necessario-baixar-as-dependencias","text":"pandas : pip install pandas matplotlib : pip install matplolib numpy : pip install numpy O WebScraper, al\u00e9m de coletar as notas dos jogos, obteve outros par\u00e2metros para fazer uma an\u00e1lise. Os par\u00e2metros coletados no projeto foram t\u00edtulo, nota, publisher, desenvolvedora e lan\u00e7amento, apresentado no arquivo json. Ap\u00f3s a coleta e o arquivo GameInformer.json criado a \u00e1nalise pode ser feita. Assim, no arquivo An\u00e1lise dos dados.ipynb est\u00e1 a an\u00e1lise do projeto. Duas an\u00e1lises foram apresentadas, a primeira foi a distribui\u00e7\u00e3o das notas dos jogos. E a segunda foi as notas dos jogos das seguintes distribuidoras: Nintendo, Sony Interactive Entertainment (Playstation) e Xbox Game Studios, para saber qual das empresas tem as melhores notas. Distribui\u00e7\u00e3o das notas dos jogos: Nintendo x Playstation x Xbox: Como mencionado anteriormente, houve uma coleta de outros par\u00e2metros pelo WebScraper, podendo futuramente fazer outros tipos de an\u00e1lises envolvendo esses dados.","title":"Primeiro \u00e9 necess\u00e1rio baixar as depend\u00eancias:"},{"location":"scraper/","text":"Scraper O scraper \u00e9 um bot de coleta de dados de p\u00e1ginas web, ele realiza a coleta em uma p\u00e1gina por meio de uma spider e para cada p\u00e1gina nova \u00e9 necess\u00e1rio criar uma nova spider. Primeiro \u00e9 necess\u00e1rio baixar as depend\u00eancias: scrapy : pip install scrapy O scraper est\u00e1 dividido cinco arquivos em uma pasta, os arquivos s\u00e3o: * settings.py para a configura\u00e7\u00e3o do bot de coleta de dados; * pipelines.py que define opra\u00e7\u00f5es de formata\u00e7\u00e3o para os dados coletados; * middlewares.py configura a opera\u00e7\u00e3o das spiders; * items.py permite customisar como os dados do site ser\u00e3o formatados; * pasta spiders \u00e9 onde ficam os arquivos com as spiders; Contribuindo: Para ajudar a com o projeto \u00e9 possivel adicionar novas spiders para abranger uma gama maior de cr\u00edticas de jogos. Adicionado Spider: * \u00c9 preciso criar um novo arquivo .py, para isso pode ser executado o comando scrapy genspider [nome do arquivo] [URL do site alvo] . Note: que o nome do arquivo de preferencia tem ser igual a nome do site escolhido. * Preencher o metodo parse da classe criada com o a estrutura que vai ser armazenada e de onde vem cada informa\u00e7\u00e3o * Adicionar pipelines de limpiza para os dados caso necess\u00e1rio Testando: Para testar se o elemento css escolhido est\u00e1 dando a resposta esperada \u00e9 possivel abrir o shell do scrapy com scrapy shell executar o comando fetch('URL') e depois executar response.css(classe).get . Para aprender mais sobre a biblioteca: https://docs.scrapy.org/en/latest/index.html","title":"Scraper"},{"location":"scraper/#scraper","text":"O scraper \u00e9 um bot de coleta de dados de p\u00e1ginas web, ele realiza a coleta em uma p\u00e1gina por meio de uma spider e para cada p\u00e1gina nova \u00e9 necess\u00e1rio criar uma nova spider.","title":"Scraper"},{"location":"scraper/#primeiro-e-necessario-baixar-as-dependencias","text":"scrapy : pip install scrapy O scraper est\u00e1 dividido cinco arquivos em uma pasta, os arquivos s\u00e3o: * settings.py para a configura\u00e7\u00e3o do bot de coleta de dados; * pipelines.py que define opra\u00e7\u00f5es de formata\u00e7\u00e3o para os dados coletados; * middlewares.py configura a opera\u00e7\u00e3o das spiders; * items.py permite customisar como os dados do site ser\u00e3o formatados; * pasta spiders \u00e9 onde ficam os arquivos com as spiders;","title":"Primeiro \u00e9 necess\u00e1rio baixar as depend\u00eancias:"},{"location":"scraper/#contribuindo","text":"Para ajudar a com o projeto \u00e9 possivel adicionar novas spiders para abranger uma gama maior de cr\u00edticas de jogos. Adicionado Spider: * \u00c9 preciso criar um novo arquivo .py, para isso pode ser executado o comando scrapy genspider [nome do arquivo] [URL do site alvo] . Note: que o nome do arquivo de preferencia tem ser igual a nome do site escolhido. * Preencher o metodo parse da classe criada com o a estrutura que vai ser armazenada e de onde vem cada informa\u00e7\u00e3o * Adicionar pipelines de limpiza para os dados caso necess\u00e1rio Testando: Para testar se o elemento css escolhido est\u00e1 dando a resposta esperada \u00e9 possivel abrir o shell do scrapy com scrapy shell executar o comando fetch('URL') e depois executar response.css(classe).get . Para aprender mais sobre a biblioteca: https://docs.scrapy.org/en/latest/index.html","title":"Contribuindo:"}]}